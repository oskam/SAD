digraph Tree {size="30,30!";
margin=0;

node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label=<limit &le; 6408.0<br/>entropy = 2.248<br/>samples = 320<br/>value = [57, 81, 82, 70, 30]>, fillcolor="#feffff"] ;
1 [label=<rating &le; 296.5<br/>entropy = 1.982<br/>samples = 256<br/>value = [57, 81, 76, 41, 1]>, fillcolor="#fbfefa"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<limit &le; 1359.5<br/>entropy = 1.756<br/>samples = 129<br/>value = [38, 55, 29, 7, 0]>, fillcolor="#e6fada"] ;
1 -> 2 ;
3 [label=<balance &le; 8.0<br/>entropy = 0.414<br/>samples = 12<br/>value = [11, 1, 0, 0, 0]>, fillcolor="#e78c4b"] ;
2 -> 3 ;
4 [label=<entropy = 0.0<br/>samples = 11<br/>value = [11, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
3 -> 4 ;
5 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0]>, fillcolor="#7be539"] ;
3 -> 5 ;
6 [label=<balance &le; 51.0<br/>entropy = 1.745<br/>samples = 117<br/>value = [27, 54, 29, 7, 0]>, fillcolor="#d9f8c7"] ;
2 -> 6 ;
7 [label=<limit &le; 2826.0<br/>entropy = 1.777<br/>samples = 67<br/>value = [10, 28, 23, 6, 0]>, fillcolor="#f0fce8"] ;
6 -> 7 ;
8 [label=<limit &le; 1492.0<br/>entropy = 1.466<br/>samples = 52<br/>value = [10, 27, 15, 0, 0]>, fillcolor="#d4f7bf"] ;
7 -> 8 ;
9 [label=<entropy = 0.0<br/>samples = 7<br/>value = [0, 7, 0, 0, 0]>, fillcolor="#7be539"] ;
8 -> 9 ;
10 [label=<age &le; 45.0<br/>entropy = 1.53<br/>samples = 45<br/>value = [10, 20, 15, 0, 0]>, fillcolor="#e9fbde"] ;
8 -> 10 ;
11 [label=<gender_Male &le; 0.5<br/>entropy = 0.98<br/>samples = 12<br/>value = [0, 7, 5, 0, 0]>, fillcolor="#d9f8c6"] ;
10 -> 11 ;
12 [label=<ethnicity_African American &le; 0.5<br/>entropy = 0.592<br/>samples = 7<br/>value = [0, 6, 1, 0, 0]>, fillcolor="#91e95a"] ;
11 -> 12 ;
13 [label=<entropy = 0.0<br/>samples = 6<br/>value = [0, 6, 0, 0, 0]>, fillcolor="#7be539"] ;
12 -> 13 ;
14 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0]>, fillcolor="#39e5c5"] ;
12 -> 14 ;
15 [label=<married_Yes &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [0, 1, 4, 0, 0]>, fillcolor="#6aecd4"] ;
11 -> 15 ;
16 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0]>, fillcolor="#7be539"] ;
15 -> 16 ;
17 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 0, 4, 0, 0]>, fillcolor="#39e5c5"] ;
15 -> 17 ;
18 [label=<limit &le; 2261.5<br/>entropy = 1.573<br/>samples = 33<br/>value = [10, 13, 10, 0, 0]>, fillcolor="#eefce5"] ;
10 -> 18 ;
19 [label=<rating &le; 180.5<br/>entropy = 1.522<br/>samples = 25<br/>value = [5, 10, 10, 0, 0]>, fillcolor="#ffffff"] ;
18 -> 19 ;
20 [label=<age &le; 68.5<br/>entropy = 1.5<br/>samples = 20<br/>value = [5, 10, 5, 0, 0]>, fillcolor="#d3f6bd"] ;
19 -> 20 ;
21 [label=<limit &le; 2010.5<br/>entropy = 1.325<br/>samples = 12<br/>value = [5, 6, 1, 0, 0]>, fillcolor="#ecfbe3"] ;
20 -> 21 ;
22 [label=<age &le; 47.5<br/>entropy = 0.918<br/>samples = 9<br/>value = [3, 6, 0, 0, 0]>, fillcolor="#bdf29c"] ;
21 -> 22 ;
23 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
22 -> 23 ;
24 [label=<age &le; 56.5<br/>entropy = 0.592<br/>samples = 7<br/>value = [1, 6, 0, 0, 0]>, fillcolor="#91e95a"] ;
22 -> 24 ;
25 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5, 0, 0, 0]>, fillcolor="#7be539"] ;
24 -> 25 ;
26 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1, 0, 0, 0]>, fillcolor="#ffffff"] ;
24 -> 26 ;
27 [label=<entropy = 0.918<br/>samples = 3<br/>value = [2, 0, 1, 0, 0]>, fillcolor="#f2c09c"] ;
21 -> 27 ;
28 [label=<ethnicity_Caucasian &le; 0.5<br/>entropy = 1.0<br/>samples = 8<br/>value = [0, 4, 4, 0, 0]>, fillcolor="#ffffff"] ;
20 -> 28 ;
29 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3, 0, 0, 0]>, fillcolor="#7be539"] ;
28 -> 29 ;
30 [label=<rating &le; 174.0<br/>entropy = 0.722<br/>samples = 5<br/>value = [0, 1, 4, 0, 0]>, fillcolor="#6aecd4"] ;
28 -> 30 ;
31 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 0, 4, 0, 0]>, fillcolor="#39e5c5"] ;
30 -> 31 ;
32 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0]>, fillcolor="#7be539"] ;
30 -> 32 ;
33 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 0, 5, 0, 0]>, fillcolor="#39e5c5"] ;
19 -> 33 ;
34 [label=<limit &le; 2440.0<br/>entropy = 0.954<br/>samples = 8<br/>value = [5, 3, 0, 0, 0]>, fillcolor="#f5cdb0"] ;
18 -> 34 ;
35 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
34 -> 35 ;
36 [label=<entropy = 0.811<br/>samples = 4<br/>value = [1, 3, 0, 0, 0]>, fillcolor="#a7ee7b"] ;
34 -> 36 ;
37 [label=<education &le; 11.5<br/>entropy = 1.273<br/>samples = 15<br/>value = [0, 1, 8, 6, 0]>, fillcolor="#d3f9f2"] ;
7 -> 37 ;
38 [label=<entropy = 0.811<br/>samples = 4<br/>value = [0, 1, 0, 3, 0]>, fillcolor="#7d7bee"] ;
37 -> 38 ;
39 [label=<balance &le; 4.0<br/>entropy = 0.845<br/>samples = 11<br/>value = [0, 0, 8, 3, 0]>, fillcolor="#83efdb"] ;
37 -> 39 ;
40 [label=<limit &le; 2968.5<br/>entropy = 0.985<br/>samples = 7<br/>value = [0, 0, 4, 3, 0]>, fillcolor="#cef8f0"] ;
39 -> 40 ;
41 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 0, 3, 0, 0]>, fillcolor="#39e5c5"] ;
40 -> 41 ;
42 [label=<entropy = 0.811<br/>samples = 4<br/>value = [0, 0, 1, 3, 0]>, fillcolor="#7d7bee"] ;
40 -> 42 ;
43 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 0, 4, 0, 0]>, fillcolor="#39e5c5"] ;
39 -> 43 ;
44 [label=<education &le; 15.5<br/>entropy = 1.5<br/>samples = 50<br/>value = [17, 26, 6, 1, 0]>, fillcolor="#dbf8c9"] ;
6 -> 44 ;
45 [label=<limit &le; 3325.5<br/>entropy = 1.368<br/>samples = 33<br/>value = [5, 22, 5, 1, 0]>, fillcolor="#afef87"] ;
44 -> 45 ;
46 [label=<education &le; 8.5<br/>entropy = 1.614<br/>samples = 13<br/>value = [5, 6, 1, 1, 0]>, fillcolor="#eefce6"] ;
45 -> 46 ;
47 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0]>, fillcolor="#3c39e5"] ;
46 -> 47 ;
48 [label=<education &le; 13.5<br/>entropy = 1.325<br/>samples = 12<br/>value = [5, 6, 1, 0, 0]>, fillcolor="#ecfbe3"] ;
46 -> 48 ;
49 [label=<balance &le; 134.0<br/>entropy = 0.971<br/>samples = 10<br/>value = [4, 6, 0, 0, 0]>, fillcolor="#d3f6bd"] ;
48 -> 49 ;
50 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3, 0, 0, 0]>, fillcolor="#7be539"] ;
49 -> 50 ;
51 [label=<age &le; 73.0<br/>entropy = 0.985<br/>samples = 7<br/>value = [4, 3, 0, 0, 0]>, fillcolor="#f8e0ce"] ;
49 -> 51 ;
52 [label=<balance &le; 400.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [4, 1, 0, 0, 0]>, fillcolor="#eca06a"] ;
51 -> 52 ;
53 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
52 -> 53 ;
54 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1, 0, 0, 0]>, fillcolor="#7be539"] ;
52 -> 54 ;
55 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2, 0, 0, 0]>, fillcolor="#7be539"] ;
51 -> 55 ;
56 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 0, 1, 0, 0]>, fillcolor="#ffffff"] ;
48 -> 56 ;
57 [label=<education &le; 9.5<br/>entropy = 0.722<br/>samples = 20<br/>value = [0, 16, 4, 0, 0]>, fillcolor="#9cec6a"] ;
45 -> 57 ;
58 [label=<limit &le; 3487.5<br/>entropy = 0.971<br/>samples = 5<br/>value = [0, 2, 3, 0, 0]>, fillcolor="#bdf6ec"] ;
57 -> 58 ;
59 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2, 0, 0, 0]>, fillcolor="#7be539"] ;
58 -> 59 ;
60 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 0, 3, 0, 0]>, fillcolor="#39e5c5"] ;
58 -> 60 ;
61 [label=<rating &le; 288.0<br/>entropy = 0.353<br/>samples = 15<br/>value = [0, 14, 1, 0, 0]>, fillcolor="#84e747"] ;
57 -> 61 ;
62 [label=<entropy = 0.0<br/>samples = 13<br/>value = [0, 13, 0, 0, 0]>, fillcolor="#7be539"] ;
61 -> 62 ;
63 [label=<entropy = 1.0<br/>samples = 2<br/>value = [0, 1, 1, 0, 0]>, fillcolor="#ffffff"] ;
61 -> 63 ;
64 [label=<student_No &le; 0.5<br/>entropy = 1.086<br/>samples = 17<br/>value = [12, 4, 1, 0, 0]>, fillcolor="#efb185"] ;
44 -> 64 ;
65 [label=<entropy = 1.0<br/>samples = 2<br/>value = [0, 1, 1, 0, 0]>, fillcolor="#ffffff"] ;
64 -> 65 ;
66 [label=<balance &le; 186.5<br/>entropy = 0.722<br/>samples = 15<br/>value = [12, 3, 0, 0, 0]>, fillcolor="#eca06a"] ;
64 -> 66 ;
67 [label=<married_No &le; 0.5<br/>entropy = 1.0<br/>samples = 6<br/>value = [3, 3, 0, 0, 0]>, fillcolor="#ffffff"] ;
66 -> 67 ;
68 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3, 0, 0, 0]>, fillcolor="#7be539"] ;
67 -> 68 ;
69 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
67 -> 69 ;
70 [label=<entropy = 0.0<br/>samples = 9<br/>value = [9, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
66 -> 70 ;
71 [label=<balance &le; 548.5<br/>entropy = 1.973<br/>samples = 127<br/>value = [19, 26, 47, 34, 1]>, fillcolor="#e3fbf7"] ;
1 -> 71 ;
72 [label=<limit &le; 5147.0<br/>entropy = 1.483<br/>samples = 51<br/>value = [2, 2, 18, 28, 1]>, fillcolor="#c4c3f7"] ;
71 -> 72 ;
73 [label=<balance &le; 305.0<br/>entropy = 1.477<br/>samples = 39<br/>value = [2, 2, 18, 17, 0]>, fillcolor="#f6fefc"] ;
72 -> 73 ;
74 [label=<rating &le; 311.5<br/>entropy = 0.811<br/>samples = 20<br/>value = [0, 0, 5, 15, 0]>, fillcolor="#7d7bee"] ;
73 -> 74 ;
75 [label=<balance &le; 95.0<br/>entropy = 0.918<br/>samples = 6<br/>value = [0, 0, 4, 2, 0]>, fillcolor="#9cf2e2"] ;
74 -> 75 ;
76 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 2, 0]>, fillcolor="#3c39e5"] ;
75 -> 76 ;
77 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 0, 4, 0, 0]>, fillcolor="#39e5c5"] ;
75 -> 77 ;
78 [label=<education &le; 18.0<br/>entropy = 0.371<br/>samples = 14<br/>value = [0, 0, 1, 13, 0]>, fillcolor="#4b48e7"] ;
74 -> 78 ;
79 [label=<entropy = 0.0<br/>samples = 13<br/>value = [0, 0, 0, 13, 0]>, fillcolor="#3c39e5"] ;
78 -> 79 ;
80 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0]>, fillcolor="#39e5c5"] ;
78 -> 80 ;
81 [label=<rating &le; 319.5<br/>entropy = 1.4<br/>samples = 19<br/>value = [2, 2, 13, 2, 0]>, fillcolor="#7feed9"] ;
73 -> 81 ;
82 [label=<rating &le; 300.5<br/>entropy = 1.522<br/>samples = 5<br/>value = [2, 2, 1, 0, 0]>, fillcolor="#ffffff"] ;
81 -> 82 ;
83 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
82 -> 83 ;
84 [label=<entropy = 0.918<br/>samples = 3<br/>value = [0, 2, 1, 0, 0]>, fillcolor="#bdf29c"] ;
82 -> 84 ;
85 [label=<rating &le; 355.0<br/>entropy = 0.592<br/>samples = 14<br/>value = [0, 0, 12, 2, 0]>, fillcolor="#5ae9cf"] ;
81 -> 85 ;
86 [label=<entropy = 0.0<br/>samples = 9<br/>value = [0, 0, 9, 0, 0]>, fillcolor="#39e5c5"] ;
85 -> 86 ;
87 [label=<education &le; 14.0<br/>entropy = 0.971<br/>samples = 5<br/>value = [0, 0, 3, 2, 0]>, fillcolor="#bdf6ec"] ;
85 -> 87 ;
88 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 0, 3, 0, 0]>, fillcolor="#39e5c5"] ;
87 -> 88 ;
89 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 2, 0]>, fillcolor="#3c39e5"] ;
87 -> 89 ;
90 [label=<rating &le; 444.5<br/>entropy = 0.414<br/>samples = 12<br/>value = [0, 0, 0, 11, 1]>, fillcolor="#4e4be7"] ;
72 -> 90 ;
91 [label=<entropy = 0.0<br/>samples = 11<br/>value = [0, 0, 0, 11, 0]>, fillcolor="#3c39e5"] ;
90 -> 91 ;
92 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 0, 1]>, fillcolor="#e539c0"] ;
90 -> 92 ;
93 [label=<rating &le; 433.5<br/>entropy = 1.828<br/>samples = 76<br/>value = [17, 24, 29, 6, 0]>, fillcolor="#ecfcf9"] ;
71 -> 93 ;
94 [label=<limit &le; 5493.5<br/>entropy = 1.77<br/>samples = 57<br/>value = [17, 23, 14, 3, 0]>, fillcolor="#ebfbe1"] ;
93 -> 94 ;
95 [label=<limit &le; 4499.0<br/>entropy = 1.691<br/>samples = 47<br/>value = [17, 16, 13, 1, 0]>, fillcolor="#fefbf9"] ;
94 -> 95 ;
96 [label=<cards &le; 2.5<br/>entropy = 0.811<br/>samples = 8<br/>value = [6, 0, 2, 0, 0]>, fillcolor="#eeab7b"] ;
95 -> 96 ;
97 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 0, 2, 0, 0]>, fillcolor="#39e5c5"] ;
96 -> 97 ;
98 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
96 -> 98 ;
99 [label=<balance &le; 671.0<br/>entropy = 1.693<br/>samples = 39<br/>value = [11, 16, 11, 1, 0]>, fillcolor="#e7fadc"] ;
95 -> 99 ;
100 [label=<limit &le; 5122.0<br/>entropy = 0.961<br/>samples = 13<br/>value = [0, 5, 8, 0, 0]>, fillcolor="#b5f5e9"] ;
99 -> 100 ;
101 [label=<ethnicity_African American &le; 0.5<br/>entropy = 0.65<br/>samples = 6<br/>value = [0, 5, 1, 0, 0]>, fillcolor="#95ea61"] ;
100 -> 101 ;
102 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5, 0, 0, 0]>, fillcolor="#7be539"] ;
101 -> 102 ;
103 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0]>, fillcolor="#39e5c5"] ;
101 -> 103 ;
104 [label=<entropy = 0.0<br/>samples = 7<br/>value = [0, 0, 7, 0, 0]>, fillcolor="#39e5c5"] ;
100 -> 104 ;
105 [label=<education &le; 17.5<br/>entropy = 1.59<br/>samples = 26<br/>value = [11, 11, 3, 1, 0]>, fillcolor="#ffffff"] ;
99 -> 105 ;
106 [label=<age &le; 70.5<br/>entropy = 1.62<br/>samples = 22<br/>value = [11, 7, 3, 1, 0]>, fillcolor="#f8ddca"] ;
105 -> 106 ;
107 [label=<balance &le; 853.5<br/>entropy = 1.574<br/>samples = 19<br/>value = [11, 4, 3, 1, 0]>, fillcolor="#f3c4a3"] ;
106 -> 107 ;
108 [label=<rating &le; 383.5<br/>entropy = 1.392<br/>samples = 9<br/>value = [4, 4, 1, 0, 0]>, fillcolor="#ffffff"] ;
107 -> 108 ;
109 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
108 -> 109 ;
110 [label=<education &le; 15.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [0, 4, 1, 0, 0]>, fillcolor="#9cec6a"] ;
108 -> 110 ;
111 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4, 0, 0, 0]>, fillcolor="#7be539"] ;
110 -> 111 ;
112 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0]>, fillcolor="#39e5c5"] ;
110 -> 112 ;
113 [label=<age &le; 39.5<br/>entropy = 1.157<br/>samples = 10<br/>value = [7, 0, 2, 1, 0]>, fillcolor="#efb083"] ;
107 -> 113 ;
114 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0]>, fillcolor="#3c39e5"] ;
113 -> 114 ;
115 [label=<limit &le; 4995.0<br/>entropy = 0.764<br/>samples = 9<br/>value = [7, 0, 2, 0, 0]>, fillcolor="#eca572"] ;
113 -> 115 ;
116 [label=<entropy = 0.918<br/>samples = 3<br/>value = [1, 0, 2, 0, 0]>, fillcolor="#9cf2e2"] ;
115 -> 116 ;
117 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0, 0, 0, 0]>, fillcolor="#e58139"] ;
115 -> 117 ;
118 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3, 0, 0, 0]>, fillcolor="#7be539"] ;
106 -> 118 ;
119 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4, 0, 0, 0]>, fillcolor="#7be539"] ;
105 -> 119 ;
120 [label=<balance &le; 797.0<br/>entropy = 1.157<br/>samples = 10<br/>value = [0, 7, 1, 2, 0]>, fillcolor="#acef83"] ;
94 -> 120 ;
121 [label=<entropy = 1.0<br/>samples = 2<br/>value = [0, 0, 1, 1, 0]>, fillcolor="#ffffff"] ;
120 -> 121 ;
122 [label=<limit &le; 5522.5<br/>entropy = 0.544<br/>samples = 8<br/>value = [0, 7, 0, 1, 0]>, fillcolor="#8ee955"] ;
120 -> 122 ;
123 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 0, 1, 0]>, fillcolor="#3c39e5"] ;
122 -> 123 ;
124 [label=<entropy = 0.0<br/>samples = 7<br/>value = [0, 7, 0, 0, 0]>, fillcolor="#7be539"] ;
122 -> 124 ;
125 [label=<balance &le; 825.0<br/>entropy = 0.913<br/>samples = 19<br/>value = [0, 1, 15, 3, 0]>, fillcolor="#6aecd4"] ;
93 -> 125 ;
126 [label=<entropy = 0.811<br/>samples = 4<br/>value = [0, 0, 1, 3, 0]>, fillcolor="#7d7bee"] ;
125 -> 126 ;
127 [label=<balance &le; 1095.5<br/>entropy = 0.353<br/>samples = 15<br/>value = [0, 1, 14, 0, 0]>, fillcolor="#47e7c9"] ;
125 -> 127 ;
128 [label=<entropy = 0.0<br/>samples = 11<br/>value = [0, 0, 11, 0, 0]>, fillcolor="#39e5c5"] ;
127 -> 128 ;
129 [label=<entropy = 0.811<br/>samples = 4<br/>value = [0, 1, 3, 0, 0]>, fillcolor="#7beed8"] ;
127 -> 129 ;
130 [label=<rating &le; 634.5<br/>entropy = 1.355<br/>samples = 64<br/>value = [0, 0, 6, 29, 29]>, fillcolor="#ffffff"] ;
0 -> 130 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
131 [label=<balance &le; 725.0<br/>entropy = 1.278<br/>samples = 45<br/>value = [0, 0, 6, 29, 10]>, fillcolor="#9594f1"] ;
130 -> 131 ;
132 [label=<entropy = 0.0<br/>samples = 6<br/>value = [0, 0, 0, 0, 6]>, fillcolor="#e539c0"] ;
131 -> 132 ;
133 [label=<student_No &le; 0.5<br/>entropy = 1.07<br/>samples = 39<br/>value = [0, 0, 6, 29, 4]>, fillcolor="#7775ed"] ;
131 -> 133 ;
134 [label=<age &le; 61.0<br/>entropy = 0.918<br/>samples = 6<br/>value = [0, 0, 0, 2, 4]>, fillcolor="#f29ce0"] ;
133 -> 134 ;
135 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 0, 0, 2, 0]>, fillcolor="#3c39e5"] ;
134 -> 135 ;
136 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 0, 0, 0, 4]>, fillcolor="#e539c0"] ;
134 -> 136 ;
137 [label=<limit &le; 6966.0<br/>entropy = 0.684<br/>samples = 33<br/>value = [0, 0, 6, 27, 0]>, fillcolor="#6765eb"] ;
133 -> 137 ;
138 [label=<balance &le; 1039.0<br/>entropy = 0.971<br/>samples = 10<br/>value = [0, 0, 6, 4, 0]>, fillcolor="#bdf6ec"] ;
137 -> 138 ;
139 [label=<ethnicity_Asian &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [0, 0, 1, 4, 0]>, fillcolor="#6d6aec"] ;
138 -> 139 ;
140 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 0, 0, 4, 0]>, fillcolor="#3c39e5"] ;
139 -> 140 ;
141 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 0, 1, 0, 0]>, fillcolor="#39e5c5"] ;
139 -> 141 ;
142 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 0, 5, 0, 0]>, fillcolor="#39e5c5"] ;
138 -> 142 ;
143 [label=<entropy = 0.0<br/>samples = 23<br/>value = [0, 0, 0, 23, 0]>, fillcolor="#3c39e5"] ;
137 -> 143 ;
144 [label=<entropy = 0.0<br/>samples = 19<br/>value = [0, 0, 0, 0, 19]>, fillcolor="#e539c0"] ;
130 -> 144 ;
}
